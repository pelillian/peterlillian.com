__NUXT_JSONP__("/thoughts", (function(a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z,A,B,C,D,E,F,G,H,I,J,K,L){return {data:[{works:[{slug:v,title:"AUTOMATED AUTHORITY",image:w,folder:v,date:"2019-07-01T00:00:00.000Z",toc:[{id:x,depth:y,text:z},{id:A,depth:y,text:B}],body:{type:"root",children:[{type:b,tag:C,props:{id:x},children:[{type:b,tag:k,props:{href:"#peter-lillian",ariaHidden:j,tabIndex:D},children:[{type:b,tag:d,props:{className:[E,F]},children:[]}]},{type:a,value:z}]},{type:a,value:c},{type:b,tag:C,props:{id:A},children:[{type:b,tag:k,props:{href:"#july-2019",ariaHidden:j,tabIndex:D},children:[{type:b,tag:d,props:{className:[E,F]},children:[]}]},{type:a,value:B}]},{type:a,value:c},{type:b,tag:"blockquote",props:{},children:[{type:a,value:c},{type:b,tag:e,props:{},children:[{type:a,value:"When Marduk commanded me to give justice to the people of\nthe land and to let them have good governance, I set forth...\nto make justice appear in the land, to destroy the evil and\nthe wicked, that the strong might not oppress the weak."}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:a,value:"---Hammurabi of Babylonia [1]"}]},{type:a,value:c}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:a,value:"All governments throughout history have been run by humans. Some have\nclaimed to serve the people of their society—others have blatantly\nserved a different goal. In the modern era, and governments play a\nlarger role in human life than ever before—everything from education to\nurban planning is a function of the state. But have the motivations of\ngovernments improved? The Bulletin of Atomic Scientists considers the\ncurrent political climate \"as worrisome as the most dangerous times of\nthe Cold War\" [2]."}]},{type:a,value:c},{type:b,tag:l,props:{},children:[{type:a,value:c},{type:b,tag:m,props:{src:w,alt:" Marduk, ruler of the gods, gives legal power to Hammurabi, king of Babylonia [3]"},children:[]},{type:b,tag:n,props:{ariaHidden:j},children:[{type:a,value:i},{type:b,tag:f,props:{},children:[{type:a,value:"Marduk, ruler of the gods, gives legal power to Hammurabi, king of Babylonia"}]},{type:a,value:i},{type:b,tag:d,props:{className:[o],dataCites:"babylon"},children:[{type:a,value:"[3]"}]}]},{type:a,value:c}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:a,value:"Climate change has gotten to the point where many experts consider it\nunavoidable [4]. Wealth inequality throughout the developed world has\nbeen getting worse [5]. Humans tend to be self-serving, fail to think\nlong-term, and exhibit bias towards members of their own groups, among\nmany other pitfalls [6]. It is this kind of flawed decision-making,\ntypical of "},{type:b,tag:f,props:{},children:[{type:a,value:"Homo sapiens"}]},{type:a,value:", that causes so much calamity."}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:a,value:"With these flaws, we won’t be ruling the Earth forever. Artificial\nIntelligence is improving by the day. According to the International\nData Corporation, global spending on AI is expected to double by 2022 to\nalmost $80 billion [7]. In the wake of this windfall, we’ll start to\nsee more intelligent systems—machines eventually capable of performing\nall tasks better than humans [8]. What then? The stakeholders in the\nfuture of AI include not only the human race, but also life on Earth and\npotentially the entire universe—we can use the utility ethics test to\nexamine these scenarios. Should we put limits on AI to keep humans\nemployed? A Luddite approach will only hold us back, as governments or\ncorporations that implement these kind of regulations will inevitably be\noutcompeted by those that do not. Even if the whole world got together\nand agreed to put anti-AI laws into place (good luck getting North Korea\nor the Mafia to agree to that anyway), what would be the purpose of\nmaking humans do jobs robots can do better? Do we still have people draw\nspreadsheets by hand?"}]},{type:a,value:c},{type:b,tag:l,props:{},children:[{type:a,value:c},{type:b,tag:m,props:{src:"luddites.jpg",alt:" Luddites, a group of textile workers, destroy the textile mills that replaced their jobs. [9]"},children:[]},{type:b,tag:n,props:{ariaHidden:j},children:[{type:a,value:i},{type:b,tag:f,props:{},children:[{type:a,value:"Luddites, a group of textile workers, destroy the textile mills that replaced their jobs."}]},{type:a,value:i},{type:b,tag:d,props:{className:[o],dataCites:"luddites"},children:[{type:a,value:"[9]"}]}]},{type:a,value:c}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:a,value:"Of course, Microsoft Excel isn’t going to revolt against us anytime\nsoon, but for the purposes of this paper we will assume that we have\nsolved the superintelligent control problem (as this is a technical\nchallenge) and are able to create friendly AI that won’t harm us."},{type:b,tag:p,props:{},children:[{type:a,value:G}]},{type:a,value:"\nThere is one job, though, that might seem smart to keep as a human\noccupation. Leadership—an especially valued human quality—will likely be\nthe last job handed over to the machines. For our own sakes, it\nshouldn’t be. Though it may scare some people, putting AI into power\nwill make a smarter, faster, and more equitable world."}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:a,value:"In order to examine these questions, we can look at an automated\nauthority from the perspective of the utility test. With a machine\ngovernment, the average person would benefit financially from an\nimproved economy—the AI’s superior financial policy would make\nrecessions much less likely and put more money in the pockets of\neveryday people [11]. In this society, as no humans work, the machines\nwill remove all social classes. With no humans working, it will be\nimpossible to maintain that some humans deserve more wealth. However,\nthis would anger the rich, as their institutions and old-boy networks\nwithin the financial system would no longer give them power. In the\nlong-term, though, the incredible abundance produced by a post-scarcity\neconomy (one where robots create endless wealth distributed equally\namong all humans) might allow everyone the type of luxuriant lifestyle\npreviously only afforded to the few [12]."}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:a,value:"We could also release the source code of this AI so that any interested\ncitizen could literally read the mind of their leader, and even vote on\ntweaks or improvements. This AI could be programmed to always act in the\nperfect interest of the people [10]. If this AI’s programming was made\nopen-source, the average person would have much more confidence in their\ngovernment, something that is sorely lacking in many human regimes\ntoday. Of course, while an AI government is great for the citizens, it\nwould be a nightmare for politicians as they would be out of a\njob—though this might not be all bad, as the European Center for the\nGovernance of Change found that already 1\u002F4 of citizens would prefer AI\nto their current politicians [13]."}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:a,value:"A true superintelligence could respond to threats instantly [10]. An\neconomic crash or surprise war would take human leaders off-guard, but\nan AI would be able to watch the situation unfold at millions of frames\nper second. The downside to this, though, is that the public won’t be\nable to react to its decisions in time to modify it. We could create\nrobust guaranteed-friendly AI (that won’t kill us), but many members of\nthe public would still hold reservations about this situation, and this\ncould make them more unhappy under the new government. Yet after\ngenerations of successful machine rule, it is unlikely that people would\ncontinue to harbor these views."}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:a,value:"One task humans are notoriously bad at is long-term planning [14], a\nkind of thinking that is a natural strength of machines [15].\nAvoidable catastrophes like climate change, which our governments have\nutterly failed to address [4], would not happen to civilizations run\nby AI, as they would be built with real long-term planning abilities.\nThis means that the Earth and the environment would greatly benefit from\ngovernments actually understanding how risky actions like logging the\nAmazon can be. With this kind of planning, governments will be able to\naddress existential risks"},{type:b,tag:p,props:{},children:[{type:a,value:H}]},{type:a,value:" like asteroid impacts or global pandemics\n[16]. An AI government would also be adept at finding and dealing with\nthreats we can’t forsee, such as dangers from other disruptive\ntechnologies (e.g. nanotech) or gamma ray bursts, any of which could\neasily wipe out life on earth [16]."}]},{type:a,value:c},{type:b,tag:l,props:{},children:[{type:a,value:c},{type:b,tag:m,props:{src:"fire.jpg",alt:" Firefighters tackle a blaze near Boston, MA. Humans tend to solve the short-term problem (fight the fire) but not the long-term problem (end climate change). [17]"},children:[]},{type:b,tag:n,props:{ariaHidden:j},children:[{type:a,value:i},{type:b,tag:f,props:{},children:[{type:a,value:"Firefighters tackle a blaze near Boston, MA. Humans tend to solve the short-term problem (fight the fire) but not the long-term problem (end climate change)."}]},{type:a,value:i},{type:b,tag:d,props:{className:[o],dataCites:"fire"},children:[{type:a,value:"[17]"}]}]},{type:a,value:c}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:a,value:"If we decided not to implement an AI government, a very different set of\noutcomes emerges. The biggest immediate issue? AI use spreads to almost\nall industries; businesses realize to stay competitive they need to\nreplace their CEOs with machines [10]. This means that suddenly we\nhave a government, which is tasked with the regulation and control of\nprivate industry, trying to keep up with AI that evolve by the hour.\nThink about how tech-illiterate our current politicians are, unable to\nask relevant questions at Facebook hearings [18]. Imagine them trying\nto control organizations run by AI at the speed of thought. They’d be\noutclassed like a monkey trying to run the circus."}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:a,value:"With government oversight of the economy made impossible, the\nultra-wealthy will be able to further entrench their position. As robots\nstart to outperform on all tasks, their owners—large corporations—will\nreap the profits instead of the average person. In the worst case the\nentirety of wealth could be controlled by a few robotic\nmega-corporations [10]. If the government is not also using the power\nof AI, these superintelligent behemoths will be able to manipulate our\nleaders at their whims. That would take us down a dark path.\nHistorically, the power of the citizen has been determined by their\nshare of the economic output [19]. Countries with educated and\neconomically productive citizenship become democracies because the\ngovernment needs its citizens for tax revenue, while countries with rich\nnatural resources (oil) become autocracies because the government\ndoesn’t need its citizens [20]. As machines replace all human labor,\nthere will be no longer an incentive for those in power to share wealth."}]},{type:a,value:c},{type:b,tag:l,props:{},children:[{type:a,value:c},{type:b,tag:m,props:{src:"rome.jpg",alt:" The wealthy Roman aristocrats, having appropriated much of the wealth of the Empire, live in decadent, luxurious paradise. [21]"},children:[]},{type:b,tag:n,props:{ariaHidden:j},children:[{type:a,value:i},{type:b,tag:f,props:{},children:[{type:a,value:"The wealthy Roman aristocrats, having appropriated much of the wealth of the Empire, live in decadent, luxurious paradise."}]},{type:a,value:i},{type:b,tag:d,props:{className:[o],dataCites:"rome"},children:[{type:a,value:"[21]"}]}]},{type:a,value:c}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:a,value:"Without an AI government bound by programming to serve the people, the\nchance whatever is left of the government falling into a nightmare\nautocracy worsens. Needless to say, this is not a situation where the\naverage person benefits."}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:a,value:"In this future, whatever superpower has faster AI will have an extreme\nadvantage in wartime, and may be able to dominate the rest of the world.\nResearchers at UC Berkeley believe that it will \"lower the threshold for\ngoing to war by making it possible to attack an enemy while incurring no\nimmediate risk\" [22]. This means that any country without an AI\ngovernment able to make rapid and effective decisions would be putting\nitself in serious jeopardy of invasion. This could have obviously\nextreme negative consequences for all stakeholders in countries without\nAI leaders, in both the short- and long-term (if there is a long-term)."}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:a,value:"But this entire paper might be useless: AI may be better at the task of\nethics itself. AI researcher Nick Bostrom writes, \"To the extent that\nethics is a cognitive pursuit, a superintelligence could do it better\nthan human thinkers.\" [15] This means AI should be the one doing the\nethical analysis of whether or not to put an AI in power. Again,\nassuming we solve the control problem, this paper will be made obsolete\nby future machines’ work. Perhaps I could have saved the effort and\nsimply written \"Let future AI solve this.\""}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:a,value:"Human ethics have developed over a long history of dealing with specific\nmoral situations involving other humans [23]. The future, however,\nwill certainly involve intelligent beings that are nonhuman. When AI\nbecomes smarter than us, we will have to think about its place in\nsociety—will we give decision-making powers to a machine? It seems that\nthe answer is uncomfortably clear: there is really no choice other than\nsome form of AI government. In the end, it may actually not matter what\nwe choose, as either our current government will evolve into an AI as we\nautomate, or a superintelligent AI programmed to help humanity will take\npower for our own good. In any case, machines are coming to rule us: if\nwe do it right, it might not be as bad as you think."}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:b,tag:d,props:{className:[g]},children:[{type:a,value:"[1] "}]},{type:b,tag:d,props:{className:[h]},children:[{type:a,value:"G. R. Driver and J. C. Miles, "},{type:b,tag:f,props:{},children:[{type:a,value:"The babylonian\nlaws"}]},{type:a,value:". Wipf; Stock Publishers, 2007."}]}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:b,tag:d,props:{className:[g]},children:[{type:a,value:"[2] "}]},{type:b,tag:d,props:{className:[h]},children:[{type:a,value:"J. Mecklin, “A new abnormal: It is still 2\nminutes to midnight, 2019 doomsday clock statement.” Chicago, IL:\nScience; Security Board, Bulletin of the Atomic Scientists, 2019."}]}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:b,tag:d,props:{className:[g]},children:[{type:a,value:"[3] "}]},{type:b,tag:d,props:{className:[h]},children:[{type:a,value:"DK Images, “Stone tablet, hammurabi’s laws.”\n2019, [Online]. Available:\n"},{type:b,tag:k,props:{href:I,rel:[q,r,s],target:t},children:[{type:a,value:I}]},{type:a,value:u}]}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:b,tag:d,props:{className:[g]},children:[{type:a,value:"[4] "}]},{type:b,tag:d,props:{className:[h]},children:[{type:a,value:"A. Ghosh, "},{type:b,tag:f,props:{},children:[{type:a,value:"The great derangement: Climate\nchange and the unthinkable"}]},{type:a,value:". Penguin UK, 2018."}]}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:b,tag:d,props:{className:[g]},children:[{type:a,value:"[5] "}]},{type:b,tag:d,props:{className:[h]},children:[{type:a,value:"K. W. Knight, J. B. Schor, and A. K. Jorgenson,\n“Wealth inequality and carbon emissions in high-income countries,”\n"},{type:b,tag:f,props:{},children:[{type:a,value:"Social Currents"}]},{type:a,value:", vol. 4, no. 5, pp. 403–412, 2017."}]}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:b,tag:d,props:{className:[g]},children:[{type:a,value:"[6] "}]},{type:b,tag:d,props:{className:[h]},children:[{type:a,value:"M. G. Haselton and D. Nettle, “The paranoid\noptimist: An integrative evolutionary model of cognitive biases,”\n"},{type:b,tag:f,props:{},children:[{type:a,value:"Personality and social psychology Review"}]},{type:a,value:", vol. 10, no. 1, pp. 47–66,\n2006."}]}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:b,tag:d,props:{className:[g]},children:[{type:a,value:"[7] "}]},{type:b,tag:d,props:{className:[h]},children:[{type:a,value:"International Data Corporation, “Worldwide\nsemiannual artificial intelligence systems spending guide,” "},{type:b,tag:f,props:{},children:[{type:a,value:"IDC Media"}]},{type:a,value:",\n2019."}]}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:b,tag:d,props:{className:[g]},children:[{type:a,value:"[8] "}]},{type:b,tag:d,props:{className:[h]},children:[{type:a,value:"N. Bostrom, “A history of transhumanist\nthought,” "},{type:b,tag:f,props:{},children:[{type:a,value:"Journal of evolution and technology"}]},{type:a,value:", vol. 14, no. 1,\n2005."}]}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:b,tag:d,props:{className:[g]},children:[{type:a,value:"[9] "}]},{type:b,tag:d,props:{className:[h]},children:[{type:a,value:"C. I. Inc., “Almanac: The luddites,” "},{type:b,tag:f,props:{},children:[{type:a,value:"CBS"}]},{type:a,value:",\nMar. 2018."}]}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:b,tag:d,props:{className:[g]},children:[{type:a,value:"[10] "}]},{type:b,tag:d,props:{className:[h]},children:[{type:a,value:"N. Bostrom, "},{type:b,tag:f,props:{},children:[{type:a,value:"Superintelligence: Paths, dangers,\nstrategies"}]},{type:a,value:". Oxford University Press, 2014."}]}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:b,tag:d,props:{className:[g]},children:[{type:a,value:"[11] "}]},{type:b,tag:d,props:{className:[h]},children:[{type:a,value:"E. Ernst, R. Merola, and D. Samaan, “The\neconomics of artificial intelligence: Implications for the future of\nwork,” "},{type:b,tag:f,props:{},children:[{type:a,value:"ILO Future of Work Research Paper Series"}]},{type:a,value:", vol. 5, p. 41,\n2018."}]}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:b,tag:d,props:{className:[g]},children:[{type:a,value:"[12] "}]},{type:b,tag:d,props:{className:[h]},children:[{type:a,value:"A. Korinek and J. E. Stiglitz, “Artificial\nintelligence and its implications for income distribution and\nunemployment,” National Bureau of Economic Research, 2017."}]}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:b,tag:d,props:{className:[g]},children:[{type:a,value:"[13] "}]},{type:b,tag:d,props:{className:[h]},children:[{type:a,value:"IE University, “European tech insights 2019,”\n"},{type:b,tag:f,props:{},children:[{type:a,value:"Center for the Governance of Change"}]},{type:a,value:", Mar. 2019, [Online]. Available:\n"},{type:b,tag:k,props:{href:J,rel:[q,r,s],target:t},children:[{type:a,value:J}]},{type:a,value:u}]}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:b,tag:d,props:{className:[g]},children:[{type:a,value:"[14] "}]},{type:b,tag:d,props:{className:[h]},children:[{type:a,value:"D. Dörner and H. Schaub, “Errors in planning\nand decision-making and the nature of human information processing,”\n"},{type:b,tag:f,props:{},children:[{type:a,value:"Applied psychology"}]},{type:a,value:", vol. 43, no. 4, pp. 433–453, 1994."}]}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:b,tag:d,props:{className:[g]},children:[{type:a,value:"[15] "}]},{type:b,tag:d,props:{className:[h]},children:[{type:a,value:"N. Bostrom, “Ethical issues in advanced\nartificial intelligence,” "},{type:b,tag:f,props:{},children:[{type:a,value:"Science Fiction and Philosophy: From Time\nTravel to Superintelligence"}]},{type:a,value:", pp. 277–284, 2003."}]}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:b,tag:d,props:{className:[g]},children:[{type:a,value:"[16] "}]},{type:b,tag:d,props:{className:[h]},children:[{type:a,value:"N. Bostrom and M. M. Cirkovic, "},{type:b,tag:f,props:{},children:[{type:a,value:"Global\ncatastrophic risks"}]},{type:a,value:". Oxford University Press, 2011."}]}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:b,tag:d,props:{className:[g]},children:[{type:a,value:"[17] "}]},{type:b,tag:d,props:{className:[h]},children:[{type:a,value:"T. Economist, “The world is losing the war\nagainst climate change,” "},{type:b,tag:f,props:{},children:[{type:a,value:"The Economist"}]},{type:a,value:K}]}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:b,tag:d,props:{className:[g]},children:[{type:a,value:"[18] "}]},{type:b,tag:d,props:{className:[h]},children:[{type:a,value:"C. Rampell, “Our politicians have no idea how\nthe internet works,” "},{type:b,tag:f,props:{},children:[{type:a,value:"The Washington Post"}]},{type:a,value:K}]}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:b,tag:d,props:{className:[g]},children:[{type:a,value:"[19] "}]},{type:b,tag:d,props:{className:[h]},children:[{type:a,value:"D. Acemoglu and J. A. Robinson, “Persistence of\npower, elites, and institutions,” "},{type:b,tag:f,props:{},children:[{type:a,value:"American Economic Review"}]},{type:a,value:", vol. 98,\nno. 1, pp. 267–93, 2008."}]}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:b,tag:d,props:{className:[g]},children:[{type:a,value:"[20] "}]},{type:b,tag:d,props:{className:[h]},children:[{type:a,value:"M. L. Ross, “Does oil hinder democracy?” "},{type:b,tag:f,props:{},children:[{type:a,value:"World\npolitics"}]},{type:a,value:", vol. 53, no. 3, pp. 325–361, 2001."}]}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:b,tag:d,props:{className:[g]},children:[{type:a,value:"[21] "}]},{type:b,tag:d,props:{className:[h]},children:[{type:a,value:"T. Couture, “Romans during the decadence.”\n1847, [Online]. Available:\n"},{type:b,tag:k,props:{href:L,rel:[q,r,s],target:t},children:[{type:a,value:L}]},{type:a,value:u}]}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:b,tag:d,props:{className:[g]},children:[{type:a,value:"[22] "}]},{type:b,tag:d,props:{className:[h]},children:[{type:a,value:"S. Russell, S. Hauert, R. Altman, and M.\nVeloso, “Ethics of artificial intelligence,” "},{type:b,tag:f,props:{},children:[{type:a,value:"Nature"}]},{type:a,value:", vol. 521, no.\n7553, pp. 415–416, 2015."}]}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:b,tag:d,props:{className:[g]},children:[{type:a,value:"[23] "}]},{type:b,tag:d,props:{className:[h]},children:[{type:a,value:"A. MacIntyre, "},{type:b,tag:f,props:{},children:[{type:a,value:"A short history of ethics: A\nhistory of moral philosophy from the homeric age to the 20th century"}]},{type:a,value:".\nRoutledge, 2003."}]}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:b,tag:p,props:{},children:[{type:a,value:G}]},{type:a,value:" A discussion of the dangers of unfriendly AI is out of scope here,\nbut the curious reader will find Nick Bostrom’s "},{type:b,tag:f,props:{},children:[{type:a,value:"Superintelligence:\nPaths, Dangers, Strategies"}]},{type:a,value:" [10] to be an enlightening overview of the\ntopic."}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:b,tag:p,props:{},children:[{type:a,value:H}]},{type:a,value:" Existential risks are risks to the continued survival of life on\nthis planet or in the universe [16]."}]}]},dir:"\u002Fthoughts",path:"\u002Fthoughts\u002Fautomated",extension:".md",createdAt:"2020-12-31T09:57:29.797Z",updatedAt:"2020-12-31T09:59:22.125Z"}]}],fetch:[],mutations:void 0}}("text","element","\n","span","p","em","csl-left-margin","csl-right-inline"," ","true","a","figure","v-img","figcaption","citation","sup","nofollow","noopener","noreferrer","_blank",".","automated","babylon.jpg","peter-lillian",2,"PETER LILLIAN","july-2019","JULY 2019","h2",-1,"icon","icon-link","1","2","https:\u002F\u002Fres.cloudinary.com\u002Fdk-find-out\u002Fimage\u002Fupload\u002Fq_80,w_1440,f_auto\u002FA-Almy-BPDGW6_q4heaf.jpg","https:\u002F\u002Fwww.ie.edu\u002Fcgc\u002Fresearch\u002Ftech-opinion-poll-2019\u002F",", Aug. 2018.","https:\u002F\u002Fcommons.wikimedia.org\u002Fwiki\u002FFile:Thomas_Couture_-_Romans_during_the_Decadence_-_Google_Art_Project.jpg")));